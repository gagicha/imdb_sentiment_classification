{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_files= os.listdir(\"train/pos/\")\n",
    "train_neg_files= os.listdir(\"train/neg\")\n",
    "test_pos_files= os.listdir(\"test/pos/\")\n",
    "test_neg_files= os.listdir(\"test/neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews=[]\n",
    "for  pfile in train_pos_files:\n",
    "    with open(\"train/pos/\"+ pfile,encoding=\"latin1\") as f:\n",
    "        train_reviews.append(f.read())\n",
    "for  nfile in train_neg_files:\n",
    "    with open(\"train/neg/\"+ nfile,encoding=\"latin1\") as f:\n",
    "        train_reviews.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_reviews=[]\n",
    "for  pfile in test_pos_files:\n",
    "    with open(\"test/pos/\"+ pfile,encoding=\"latin1\") as f:\n",
    "        test_reviews.append(f.read())\n",
    "for  nfile in test_neg_files:\n",
    "    with open(\"test/neg/\"+ nfile,encoding=\"latin1\") as f:\n",
    "        test_reviews.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_reviews))\n",
    "print(len(test_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stopwords and remove common punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]*\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    out=[]\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", review.lower()) for review in reviews]\n",
    "#     for review in reviews:\n",
    "#         out.append(\" \".join([word for word in review.split() if word not in stopWords]))\n",
    "    return [\" \".join([word for word in review.split() if word not in stopWords]) for review in reviews]\n",
    "\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(train_reviews)\n",
    "reviews_test_clean = preprocess_reviews(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie gets respect sure lot memorable quotes listed gem imagine movie joe piscopo actually funny maureen stapleton scene stealer moroni character absolute scream watch alan skipper hale jr police sgt',\n",
       " 'bizarre horror movie filled famous faces stolen cristina raines later tvs flamingo road pretty somewhat unstable model gummy smile slated pay attempted suicides guarding gateway hell scenes raines modeling well captured mood music perfect deborah raffin charming cristinas pal raines moves creepy brooklyn heights brownstone inhabited blind priest top floor things really start cooking neighbors including fantastically wicked burgess meredith kinky couple sylvia miles & beverly dangelo diabolical lot eli wallach great fun wily police detective movie nearly cross-pollination rosemarys baby exorcist--but combination based best-seller jeffrey konvitz sentinel entertainingly spooky full shocks brought well director michael winner mounts thoughtfully downbeat ending skill ***1/2 ****',\n",
       " 'solid unremarkable film matthau einstein wonderful favorite part thing would make go way see wonderful scene physicists playing badmitton loved sweaters conversation waited robbins retrieve birdie']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews = get_stemmed_text(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movi get respect sure lot memor quot list gem imagin movi joe piscopo actual funni maureen stapleton scene stealer moroni charact absolut scream watch alan skipper hale jr polic sgt',\n",
       " 'bizarr horror movi fill famou face stolen cristina rain later tv flamingo road pretti somewhat unstabl model gummi smile slate pay attempt suicid guard gateway hell scene rain model well captur mood music perfect deborah raffin charm cristina pal rain move creepi brooklyn height brownston inhabit blind priest top floor thing realli start cook neighbor includ fantast wick burgess meredith kinki coupl sylvia mile & beverli dangelo diabol lot eli wallach great fun wili polic detect movi nearli cross-pollin rosemari babi exorcist--but combin base best-sel jeffrey konvitz sentinel entertainingli spooki full shock brought well director michael winner mount thought downbeat end skill ***1/2 ****',\n",
       " 'solid unremark film matthau einstein wonder favorit part thing would make go way see wonder scene physicist play badmitton love sweater convers wait robbin retriev birdi']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_reviews[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear classifiers typically perform better on sparse data(lots of zeroes). we can also try SVM with linear kernel on this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87744\n",
      "Accuracy for C=0.05: 0.88448\n",
      "Accuracy for C=0.25: 0.88624\n",
      "Accuracy for C=0.5: 0.88576\n",
      "Accuracy for C=1: 0.88544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we used a binary count to tell if a word is present or not, next we will actually count the frequency of each word. This has increase our accuracy by 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.88592\n",
      "Accuracy for C=0.05: 0.8944\n",
      "Accuracy for C=0.25: 0.89424\n",
      "Accuracy for C=0.5: 0.89424\n",
      "Accuracy for C=1: 0.89344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=False, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1922798)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for c=0.25, acc=max; .886"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use tf-idf for feature respresentations. tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in — where words that appear in many documents have a value closer to zero and words that appear in less documents have values closer to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.79888\n",
      "Accuracy for C=0.05: 0.84064\n",
      "Accuracy for C=0.25: 0.87696\n",
      "Accuracy for C=0.5: 0.88848\n",
      "Accuracy for C=1: 0.89472\n",
      "Final Accuracy: 0.88388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "# Accuracy for C=0.01: 0.79632\n",
    "# Accuracy for C=0.05: 0.83168\n",
    "# Accuracy for C=0.25: 0.86768\n",
    "# Accuracy for C=0.5: 0.8736\n",
    "# Accuracy for C=1: 0.88432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88388\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.89104\n",
      "Accuracy for C=0.05: 0.88704\n",
      "Accuracy for C=0.25: 0.88512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagicha/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.8848\n",
      "Accuracy for C=1: 0.88496\n",
      "Final Accuracy: 0.88644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=False, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.89104\n",
    "# Accuracy for C=0.05: 0.88736\n",
    "# Accuracy for C=0.25: 0.8856\n",
    "# Accuracy for C=0.5: 0.88608\n",
    "# Accuracy for C=1: 0.88592\n",
    "    \n",
    "final_svm_ngram = LinearSVC(C=0.01)\n",
    "final_svm_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for us, logistic regressioon with count vectorizer binary=False with n-grams (1,2) worked best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
